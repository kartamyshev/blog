{"pageProps":{"post":{"id":11,"contentHTML":"\n### The history of typeof null\n\n> The [first JavaScript engine](http://mxr.mozilla.org/classic/source/js/src/jsapi.h)\n> represented JavaScript values as 32-bit words.\n> The lowest 3 bits of such a word were used as a type tag, to indicate whether\n> the value was an object, an integer, a double, a string, or a boolean\n> (as you can see, even this early engine already stored numbers as integers if possible).\n>\n> The type tag for objects was 000. In order to represent the value null, the engine used the\n> machine language NULL pointer, a word where all bits are zero. typeof checked the\n> type tag to determine the type of value, which is why it reported null to be an object.\n\n\n\n### History: Why are objects always truthy?\n\n> The conversion to boolean is different for historic reasons. For ECMAScript 1,\n> it was decided to not enable objects to configure that conversion (e.g., via a toBoolean() method).\n> The rationale was that the boolean operators || and && preserve the values of their operands.\n> Therefore, if you chain those operators, the same value may be checked multiple times for\n> truthiness or falsiness. Such checks are cheap for primitives, but would be costly for\n> objects if they were able to configure their conversion to boolean. ECMAScript\n> 1 avoided that cost by making objects always truthy.","title":"Useful quotations from \"Speaking Javascript\" book ","published":false,"date":"2015-03-22 09:46:42"}},"__N_SSG":true}